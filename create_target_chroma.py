import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from rag_utils_target import add_document_to_target_collection, get_or_create_target_collection



PDF_FOLDER = "./target_pdfs"

# ------------------------------------------------------
# 1. PDF ë¡œë“œ (ì‹ ê·œ íŒŒì¼ë§Œ)
# ------------------------------------------------------
def load_pdfs():
    docs = []

    print("PDF í´ë” ìŠ¤ìº” ì¤‘...")
    pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.lower().endswith(".pdf")]

    if not pdf_files:
        raise Exception("target_pdfs í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    print(f"í´ë” ë‚´ ëª¨ë“  PDF: {pdf_files}")

    # --- ê¸°ì¡´ DBì—ì„œ ì´ë¯¸ ì €ì¥ëœ filename ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ---
    collection = get_or_create_target_collection()
    existing_files = set()

    if collection is not None:
        data = collection.get(include=["metadatas"])
        for item in data["metadatas"]:
            if item and "filename" in item:
                existing_files.add(item["filename"])

    print("ì´ë¯¸ ì¸ë±ì‹±ëœ íŒŒì¼:", existing_files)

    # --- ì‹ ê·œ PDFë§Œ ì„ íƒ ---
    new_pdfs = [f for f in pdf_files if f not in existing_files]

    if not new_pdfs:
        print("â¡ï¸ ìƒˆë¡œìš´ PDF ì—†ìŒ. ì¸ë±ì‹± ìŠ¤í‚µ!")
        return docs

    print("ì‹ ê·œ ì¸ë±ì‹± ëŒ€ìƒ PDF:", new_pdfs)

    # --- ì‹ ê·œ PDF ë¡œë“œ ---
    for pdf in new_pdfs:
        pdf_path = os.path.join(PDF_FOLDER, pdf)
        print(f"\nğŸ“„ ë¡œë“œ ì¤‘: {pdf_path}")

        loader = PyPDFLoader(pdf_path)
        pdf_docs = loader.load()

        print(f"- í˜ì´ì§€ ìˆ˜: {len(pdf_docs)}")

        # meta ì •ë³´ì— filename ì €ì¥
        for d in pdf_docs:
            d.metadata["filename"] = pdf

        docs.extend(pdf_docs)

    print(f"\nì‹ ê·œ ë¡œë“œëœ ë¬¸ì„œ ì´ ìˆ˜: {len(docs)}ê°œ")
    return docs


# ------------------------------------------------------
# 2. ì²­í¬ ìƒì„±
# ------------------------------------------------------
def split_chunks(docs):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=200,
        chunk_overlap=50
    )

    chunks = splitter.split_documents(docs)
    print(f"ìƒì„±ëœ ì „ì²´ ì²­í¬: {len(chunks)}")
    return chunks


# ------------------------------------------------------
# 3. ChromaDB ì €ì¥
# ------------------------------------------------------
def save_to_chroma(chunks):
    texts = [chunk.page_content for chunk in chunks]
    metadatas = [
        {
            "source_type": "íƒ€ê²Ÿë¶„ë¥˜",
            "filename": chunk.metadata.get("filename", "unknown"),
            "page": chunk.metadata.get("page", None)
        }
        for chunk in chunks
    ]
    ids = [f"target_chunk_{i}" for i in range(len(chunks))]

    print("ChromaDB ì €ì¥ ì¤‘...")
    add_document_to_target_collection(
        documents=texts,
        metadatas=metadatas,
        ids=ids
    )
    print("ì €ì¥ ì™„ë£Œ!")


# ------------------------------------------------------
# 4. ì‹¤í–‰
# ------------------------------------------------------
if __name__ == "__main__":
    print("PDF ë¡œë“œ ì¤‘...")
    docs = load_pdfs()

    if not docs:
        print("ì‹ ê·œ ë¬¸ì„œ ì—†ìŒ â†’ í”„ë¡œê·¸ë¨ ì¢…ë£Œ.")
        exit()

    print("ì²­í¬ ë¶„í•  ì¤‘...")
    chunks = split_chunks(docs)

    print("DB ì €ì¥ ì‹œì‘")
    save_to_chroma(chunks)

    print("\nì „ì²´ ingest ì™„ë£Œ!")
